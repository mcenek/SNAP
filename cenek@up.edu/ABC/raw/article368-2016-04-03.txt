
A computer that can decipher your emotions could help online advertisers target you at times when you're most likey to be receptive to their message
Your computer may soon be able to tell what you're thinking by picking up on expressions like a raised eyebrow, a nod of the head or an angry glare, scientists say.
British and American researchers are developing an "emotionally aware" computer that will be able to read an individual's mind by analysing a combination of facial movements that represent feelings.
The technology will be unveiled at a science exhibition in London today. 
"The system we have developed allows a wide range of mental states to be identified just by pointing a video camera at someone," says Professor Peter Robinson, of the University of Cambridge in England.
He and his collaborators believe the mind-reading computer's applications could range from improving people's driving skills to helping companies tailor advertising to people's moods.
"Imagine a computer that could pick the right emotional moment to try to sell you something, a future where mobile phones, cars and Web sites could read our mind and react to our moods," he says. 
The technology is already programmed to recognise different facial expressions generated by actors.
Robinson hopes to get more data to determine whether someone is bored, interested, confused, or agrees or disagrees.
Visitors to the four-day exhibition organised by The Royal Society, Britain's academy of leading scientists, will be invited to take part in a study to hone the program's abilities.
Encoding boredom, tiredness, confusion
The scientists, who are developing the technology in collaboration with researchers at the Massachusetts Institute of Technology (MIT) in the United States, also hope to get it to accept other inputs such as posture and gesture. 
"Our research could enable Web sites to tailor advertising or products to your mood," Robinson says.
"For example, a webcam linked with our software could process your image, encode the correct emotional state and transmit information to a Web site." 
It could also be useful in online teaching to show whether someone understands what is being explained and in improving road safety by determining if a driver is confused, bored or tired. 
"We are working with a big car company and they envision this being employed in cars within five years," Robinson says, adding that a camera could be built into the dashboard. 
Anyone who doesn't want to give away too much information about what they are feeling can just cover up the camera, he says.
